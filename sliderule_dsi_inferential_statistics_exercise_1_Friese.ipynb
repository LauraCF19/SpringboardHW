{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the True Normal Human Body Temperature? \n",
    "\n",
    "#### Background\n",
    "\n",
    "The mean normal body temperature was held to be 37$^{\\circ}$C or 98.6$^{\\circ}$F for more than 120 years since it was first conceptualized and reported by Carl Wunderlich in a famous 1868 book. But, is this value statistically correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercises</h3>\n",
    "\n",
    "<p>In this exercise, you will analyze a dataset of human body temperatures and employ the concepts of hypothesis testing, confidence intervals, and statistical significance.</p>\n",
    "\n",
    "<p>Answer the following questions <b>in this notebook below and submit to your Github account</b>.</p> \n",
    "\n",
    "<ol>\n",
    "<li>  Is the distribution of body temperatures normal? \n",
    "    <ul>\n",
    "    <li> Although this is not a requirement for the Central Limit Theorem to hold (read the introduction on Wikipedia's page about the CLT carefully: https://en.wikipedia.org/wiki/Central_limit_theorem), it gives us some peace of mind that the population may also be normally distributed if we assume that this sample is representative of the population.\n",
    "    <li> Think about the way you're going to check for the normality of the distribution. Graphical methods are usually used first, but there are also other ways: https://en.wikipedia.org/wiki/Normality_test\n",
    "    </ul>\n",
    "<li>  Is the sample size large? Are the observations independent?\n",
    "    <ul>\n",
    "    <li> Remember that this is a condition for the Central Limit Theorem, and hence the statistical tests we are using, to apply.\n",
    "    </ul>\n",
    "<li>  Is the true population mean really 98.6 degrees F?\n",
    "    <ul>\n",
    "    <li> First, try a bootstrap hypothesis test.\n",
    "    <li> Now, let's try frequentist statistical testing. Would you use a one-sample or two-sample test? Why?\n",
    "    <li> In this situation, is it appropriate to use the $t$ or $z$ statistic? \n",
    "    <li> Now try using the other test. How is the result be different? Why?\n",
    "    </ul>\n",
    "<li>  Draw a small sample of size 10 from the data and repeat both frequentist tests. \n",
    "    <ul>\n",
    "    <li> Which one is the correct one to use? \n",
    "    <li> What do you notice? What does this tell you about the difference in application of the $t$ and $z$ statistic?\n",
    "    </ul>\n",
    "<li>  At what temperature should we consider someone's temperature to be \"abnormal\"?\n",
    "    <ul>\n",
    "    <li> As in the previous example, try calculating everything using the boostrap approach, as well as the frequentist approach.\n",
    "    <li> Start by computing the margin of error and confidence interval. When calculating the confidence interval, keep in mind that you should use the appropriate formula for one draw, and not N draws.\n",
    "    </ul>\n",
    "<li>  Is there a significant difference between males and females in normal temperature?\n",
    "    <ul>\n",
    "    <li> What testing approach did you use and why?\n",
    "    <li> Write a story with your conclusion in the context of the original problem.\n",
    "    </ul>\n",
    "</ol>\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "#### Resources\n",
    "\n",
    "+ Information and data sources: http://www.amstat.org/publications/jse/datasets/normtemp.txt, http://www.amstat.org/publications/jse/jse_data_archive.htm\n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/human_body_temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temperature gender  heart_rate\n",
      "0         99.3      F        68.0\n",
      "1         98.4      F        81.0\n",
      "2         97.8      M        73.0\n",
      "3         99.2      F        66.0\n",
      "4         98.0      F        73.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9865770936012268, 0.233174666762352)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "## Checking whether the distribution of the df is normal:\n",
    "import scipy.stats as stats\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "stats.shapiro(df.temperature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we see here that the results of the Shapiro test for normality. The second value there is the p, which is 0.23. This is higher than the usual cutoff, 0.05, and so we fail to reject the null hypothesis that the distribution is normal. I'll double check these results using a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f3f50b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df.temperature)\n",
    "             \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks somewhat normal, although there do appear to be some outliers over 100. But this combines with the results of the Shapiro-Wilk test are enough to imply that the body temperature of this dataset is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "len(df) #this will give us the number of samples, and thus the sample size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "130 observations is much larger than the 30 needed in order for a sample to be considered large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909.4347952312239,\n",
       " 0.967631309911425,\n",
       " 990,\n",
       " array([[0.01538462, 0.00769231, 0.00769231, ..., 0.01538462, 0.00769231,\n",
       "         0.01538462],\n",
       "        [0.01538462, 0.00769231, 0.00769231, ..., 0.01538462, 0.00769231,\n",
       "         0.01538462],\n",
       "        [0.03076923, 0.01538462, 0.01538462, ..., 0.03076923, 0.01538462,\n",
       "         0.03076923],\n",
       "        ...,\n",
       "        [0.01538462, 0.00769231, 0.00769231, ..., 0.01538462, 0.00769231,\n",
       "         0.01538462],\n",
       "        [0.01538462, 0.00769231, 0.00769231, ..., 0.01538462, 0.00769231,\n",
       "         0.01538462],\n",
       "        [0.01538462, 0.00769231, 0.00769231, ..., 0.01538462, 0.00769231,\n",
       "         0.01538462]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this performs a chi squared test of independence, which will calculate the liklihood of independence\n",
    "\n",
    "crosstab1 = pd.crosstab(df['temperature'], df['heart_rate'])\n",
    "\n",
    "stats.chi2_contingency(crosstab1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.144877344877344, 0.83459920689748, 33, array([[0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [1.5, 1.5],\n",
       "        [1.5, 1.5],\n",
       "        [0.5, 0.5],\n",
       "        [2.5, 2.5],\n",
       "        [1. , 1. ],\n",
       "        [2. , 2. ],\n",
       "        [1.5, 1.5],\n",
       "        [3.5, 3.5],\n",
       "        [2.5, 2.5],\n",
       "        [5.5, 5.5],\n",
       "        [1.5, 1.5],\n",
       "        [5. , 5. ],\n",
       "        [2.5, 2.5],\n",
       "        [4.5, 4.5],\n",
       "        [1.5, 1.5],\n",
       "        [5. , 5. ],\n",
       "        [4. , 4. ],\n",
       "        [5. , 5. ],\n",
       "        [1. , 1. ],\n",
       "        [2.5, 2.5],\n",
       "        [1.5, 1.5],\n",
       "        [1.5, 1.5],\n",
       "        [1. , 1. ],\n",
       "        [1. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we check whether temp and gender are independent\n",
    "crosstab2 = pd.crosstab(df['temperature'], df['gender'])\n",
    "stats.chi2_contingency(crosstab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34.695238095238096, 0.2538983650429774, 30, array([[1. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 1. ],\n",
       "        [1. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [3. , 3. ],\n",
       "        [1.5, 1.5],\n",
       "        [2. , 2. ],\n",
       "        [1. , 1. ],\n",
       "        [3. , 3. ],\n",
       "        [3. , 3. ],\n",
       "        [3.5, 3.5],\n",
       "        [3. , 3. ],\n",
       "        [2.5, 2.5],\n",
       "        [5. , 5. ],\n",
       "        [3. , 3. ],\n",
       "        [2.5, 2.5],\n",
       "        [1.5, 1.5],\n",
       "        [3.5, 3.5],\n",
       "        [5. , 5. ],\n",
       "        [3.5, 3.5],\n",
       "        [2. , 2. ],\n",
       "        [2.5, 2.5],\n",
       "        [2.5, 2.5],\n",
       "        [2. , 2. ],\n",
       "        [2. , 2. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 1. ],\n",
       "        [0.5, 0.5],\n",
       "        [1. , 1. ]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lastly, we check whether heart rate and gender are independent\n",
    "crosstab3 = pd.crosstab(df['heart_rate'], df['gender'])\n",
    "stats.chi2_contingency(crosstab3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-values are the second stat of the first line of output. They are: 0.967631309911425, 0.83459920689748, and 0.2538983650429774. These figures are all above the traditional cutoff of 0.05, and this we fail to reject the null hypothesis. This implies that there is likely no relationship between any of the three variables, and thus we can say that they are likley independent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p =  0.0\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "# Okay, so we're doing a bootstrap hypothesis test to determine whether the true population mean temperature is 98.6\n",
    "# we need to first define the draw bs reps function and the bootstrap_replicate_1d, so we can use them to draw boostrap samples:\n",
    "\n",
    "def bootstrap_replicate_1d(data, func):\n",
    "     \"\"\"Generate bootstrap replicate of 1D data.\"\"\"\n",
    "     bs_sample = np.random.choice(data, len(data))\n",
    "     return func(bs_sample)\n",
    "\n",
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "\n",
    "    return bs_replicates\n",
    "\n",
    "# so we're going to make a translated array from which to draw replicates from, and then test those means against the\n",
    "# mean of the observed data. Then we will determine (using p) whether the difference between the two is statistically significant\n",
    "\n",
    "# Make an array of translated impact forces: translated_force_b\n",
    "translated_temp = df.temperature - np.mean(df.temperature) + 98.6 # we translate because we're testing whether the mean = 0.55\n",
    "\n",
    "bs_replicates = draw_bs_reps(translated_temp, np.mean, 10000)\n",
    "\n",
    "p = np.sum(bs_replicates <= np.mean(df.temperature)) / 10000\n",
    "\n",
    "# Print the p-value\n",
    "print('p = ', p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the p value is very small (0). This indicates that we can reject the null hypothesis that the true population mean temperature is 98.6. This indicates that the true population mean temperature is likley less than 98.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use a one-sample test, as we're only testing the true mean of one variable, not the difference or relationship between two variables. I would also use the z statistic as this sample has a large sample size (130), and the sample size is over the cutoff (30) under which we would use a t test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.4548232923645195, 4.9021570141012155e-08)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we'll conduct the z test!\n",
    "\n",
    "import statsmodels.stats.weightstats as ssw\n",
    "\n",
    "ssw.ztest(df.temperature, value=98.6, alternative='two-sided')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here are the results. The first result is the z-score and the second is the p value. Here we can see that the p value is very small (almost 0). This confirms our earlier test. We can reject the null hypothesis that the mean temperature is 98.6, and say the true population mean is statistically significantly different from 98.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98.1 98.7 98.6 98.8 98.6 98.4 96.3 98.6 98.3 99. ]\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "# First we draw the small random sample of 10:\n",
    "\n",
    "np.random.seed(7654567)\n",
    "\n",
    "sample = np.random.choice(df.temperature, 10)\n",
    "\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0812495973528047, 0.2795861011938462)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we run a z test and a t test on this small sample and compare them:\n",
    "# first, the z test\n",
    "ssw.ztest(sample, value=98.6, alternative='two-sided')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the p is much higher. That could make the data misleading, as our more sound test had a very low p value. Let's compare this to the t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-1.081249597352805, pvalue=0.30770570322201435)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The t test: (the default alternative is two sided)\n",
    "\n",
    "stats.ttest_1samp(sample, 98.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a very similar p value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval = [98.12230769 98.37538462]\n"
     ]
    }
   ],
   "source": [
    "# 5 \n",
    "#This problem involves creating a confidence interval. Any temperature that falls outside of that interval\n",
    "# would be considered abnormal. \n",
    "\n",
    "# The first confidence interval I'm going to create will be done using boostrapping. We first define a function that\n",
    "# will draw boostrap replicates and calculate the function specified for each sample\n",
    "\n",
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "\n",
    "    return bs_replicates\n",
    "\n",
    "bs_replicates = draw_bs_reps(df.temperature, np.mean, 10000)\n",
    "\n",
    "conf_int = np.percentile(bs_replicates, [2.5, 97.5])\n",
    "\n",
    "print('95% confidence interval =', conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So bootstrapping gave us a CI of (98.12, 98.37), so any temperature outside of that interval would be considered abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.126538465000003"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we calculate the margin of error:\n",
    "\n",
    "(98.37538462 - 98.12230769)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOE = 0.13, very small. Let's try the frequentist approach next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.5229207184351, 98.97554082002645)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CI the frequintist way!\n",
    "\n",
    "mu, sigma = np.mean(df.temperature), np.std(df.temperature)\n",
    "\n",
    "\n",
    "# NOTE, we're using the formula for a single draw, so we don't divide sigma by the sqrt of N\n",
    "stats.norm.interval(0.68, loc=mu, scale=sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726310050795675"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Margin of error:\n",
    "\n",
    "(98.97554082002645 - 97.5229207184351)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a much wider confidence interval, (97.52, 98.98). The margin of error is also much larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "# First, let's seperate the boys and the girls\n",
    "\n",
    "boys = df.temperature[df.gender == 'M']\n",
    "\n",
    "girls = df.temperature[df.gender == 'F']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.9872\n"
     ]
    }
   ],
   "source": [
    "# Now, we'll define a function that calculates the difference of means:\n",
    "\n",
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "\n",
    "    # The difference of means of data_1, data_2: diff\n",
    "    diff = np.mean(data_1) - np.mean(data_2)\n",
    "\n",
    "    return diff\n",
    "\n",
    "# another function is needed: one that generates a permutation sample from two datasets. This creates another array \n",
    "# of the same size and then splits it acording to the lengths of the two original datasets\n",
    "\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "\n",
    "    # Concatenate the data sets: data\n",
    "    data = np.concatenate((data1, data2))\n",
    "\n",
    "    # Permute the concatenated array: permuted_data\n",
    "    permuted_data = np.random.permutation(data)\n",
    "\n",
    "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "\n",
    "    return perm_sample_1, perm_sample_2\n",
    "\n",
    "# we'll also define a function that generates many permutation replicates, so we can gather many sample statistics\n",
    "\n",
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: perm_replicates\n",
    "    perm_replicates = np.empty(size)\n",
    "\n",
    "    for i in range(size):\n",
    "        # Generate permutation sample\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "\n",
    "        # Compute the test statistic\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "\n",
    "    return perm_replicates\n",
    "\n",
    "# Now we'll use boostrapping to determine whether the means for these two groups are equal, \n",
    "# AKA whether the true mean of the difference between the means is 0\n",
    "\n",
    "# Compute difference of mean impact force from experiment: empirical_diff_means\n",
    "empirical_diff_means = diff_of_means(boys, girls)\n",
    "\n",
    "# Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(boys, girls,\n",
    "                                 diff_of_means, size=10000)\n",
    "\n",
    "# Compute p-value: p\n",
    "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)\n",
    "\n",
    "# Print the result\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the high p value (0.9872) means that we fail to reject the null hypothesis, which is that there is no difference between the mean body temperatures of men and woman. Therefore, nothing in our data suggests that there is a statistically significant difference between the mean body temperatures of men and women. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
